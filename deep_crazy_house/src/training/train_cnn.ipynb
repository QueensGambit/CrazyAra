{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import sys\n",
    "sys.path.insert(0,'../../../')\n",
    "import DeepCrazyhouse.src.runtime.Colorer\n",
    "import logging\n",
    "import mxnet as mx\n",
    "from mxnet import gluon\n",
    "from mxnet import autograd as ag\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from time import time\n",
    "import datetime\n",
    "import random\n",
    "from DeepCrazyhouse.src.domain.crazyhouse.input_representation import board_to_planes, planes_to_board\n",
    "from DeepCrazyhouse.src.domain.crazyhouse.output_representation import policy_to_moves, policy_to_best_move, policy_to_move\n",
    "from DeepCrazyhouse.src.domain.preprocessing.util import load_pgn_dataset\n",
    "import chess\n",
    "import re\n",
    "from time import time\n",
    "from DeepCrazyhouse.src.domain.neural_net.architectures.AlphaZeroResnet import AlphaZeroResnet\n",
    "from DeepCrazyhouse.src.domain.neural_net.architectures.Rise import Rise\n",
    "from DeepCrazyhouse.src.domain.preprocessing.PGNRecordDataset import PGNRecordDataset\n",
    "from DeepCrazyhouse.configs.main_config import main_config\n",
    "from mxboard import SummaryWriter\n",
    "from tqdm import tqdm_notebook\n",
    "import os\n",
    "from mxnet import nd, autograd\n",
    "from collections import deque\n",
    "from copy import deepcopy\n",
    "from multiprocessing import cpu_count\n",
    "from DeepCrazyhouse.configs.main_config import main_config\n",
    "from DeepCrazyhouse.src.training.TrainerAgent import TrainerAgent, evaluate_metrics, acc_sign, reset_metrics\n",
    "\n",
    "from DeepCrazyhouse.src.training.lr_schedules.lr_schedules import *\n",
    "import glob\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set the context on CPU, switch to GPU if there is one available (strongly recommended for training)\n",
    "ctx = mx.gpu()\n",
    "# set a specific seed value for reproducability\n",
    "seed = 72\n",
    "\n",
    "export_weights = True\n",
    "log_metrics_to_tensorboard = True\n",
    "export_grad_histograms = True\n",
    "\n",
    "batch_steps = 1000\n",
    "k_steps_initial = 231\n",
    "symbol_file = 'model-1.26031-0.589-symbol.json'\n",
    "params_file = 'model-1.26031-0.589-0231.params'\n",
    "\n",
    "batch_size = 1024 # the batch_size needed to be reduced to 1024 in order to fit in the GPU 1080Ti\n",
    "#4096 was originally used in the paper -> works slower for current GPU\n",
    "# 2048 was used in the paper Mastering the game of Go without human knowledge and fits in GPU memory\n",
    "#typically if you half the batch_size, you should double the lr\n",
    "\n",
    "# otimization parameters\n",
    "max_lr = 0.0005\n",
    "min_lr = 0.00001\n",
    "max_momentum = 0.95\n",
    "min_momentum = 0.8\n",
    "use_spike_recovery = True\n",
    "# stop training as soon as max_spikes has been reached\n",
    "max_spikes = 20\n",
    "# define spike threshold when the detection will be triggered\n",
    "spike_thresh = 1.5\n",
    "wd = 3e-5 #1e-4\n",
    "val_loss_factor = 0.5\n",
    "policy_loss_factor = 0.5\n",
    "\n",
    "normalize = True # define whether to normalize input data to [0,1]\n",
    "# one iteration is defined by passing 1 batch and doing backprop\n",
    "nb_it_per_epoch = 30500 # define how many iterations per epoch exist\n",
    "total_it = int(nb_it_per_epoch * 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fixing the random seed\n",
    "mx.random.seed(seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a ./logs and ./weights directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir ./logs && mkdir ./weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define a Learning Rate schedule\n",
    "* Here we apply a fine tuning schedule with a very low learning rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_schedule = CosineAnnealingSchedule(min_lr, max_lr, total_it*.7)\n",
    "lr_schedule = LinearWarmUp(lr_schedule, start_lr=min_lr, length=total_it*.25)\n",
    "plot_schedule(lr_schedule, iterations=total_it, ylim=[-min_lr, max_lr*1.1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Momentum schedule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "momentum_schedule = MomentumSchedule(lr_schedule, min_lr, max_lr, min_momentum, max_momentum)\n",
    "plot_schedule(momentum_schedule, iterations=total_it, ylabel='Momentum')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### load the config file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(main_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CPU_COUNT = cpu_count()\n",
    "CPU_COUNT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### load the dataset-files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Validation Dataset (which is used during training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s_idcs_val, x_val, yv_val, yp_val, pgn_datasets_val = load_pgn_dataset(dataset_type='val', part_id=0,\n",
    "                                                                           print_statistics=True, print_parameters=True, normalize=normalize)\n",
    "val_dataset = gluon.data.ArrayDataset(nd.array(x_val), nd.array(yv_val), nd.array(yp_val.argmax(axis=1)))\n",
    "val_data = gluon.data.DataLoader(val_dataset, batch_size, shuffle=False, num_workers=CPU_COUNT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(len(x_val) * 554) / batch_size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape = x_val[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yp_val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    del net\n",
    "except:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the pretrained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = gluon.nn.SymbolBlock.imports(symbol_file='weights/%s'%symbol_file, input_names='data', param_file='weights/%s'%params_file, ctx=ctx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#net = Rise(n_labels=yp_val.shape[1], channels=256, channels_value_head=8, channels_policy_head=16, nb_res_blocksX=7, nb_res_blocksX_neck=12, cardinality=1, cardinality_neck=2, value_fc_size=256, bn_mom=0.9, act_type='lrelu', use_se=True, res_scale_fac=0.2, use_rise_stem=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Network summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(net)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "mx.viz.plot_network(\n",
    "    net(mx.sym.var('data'))[1], \n",
    "    shape={'data':(1, input_shape[0], input_shape[1], input_shape[2])},\n",
    "    node_attrs={\"shape\":\"oval\",\"fixedsize\":\"false\"}\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mx.viz.print_summary(\n",
    "    net(mx.sym.var('data'))[1], \n",
    "    shape={'data':(1, input_shape[0], input_shape[1], input_shape[2])},\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#net.collect_params().initialize(mx.init.Xavier(rnd_type='uniform', factor_type='avg', magnitude=2.24), ctx=ctx)\n",
    "#net.hybridize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_parts = len(glob.glob(main_config['planes_train_dir'] + '**/*'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_parts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define the metrics to use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = {\n",
    "    'value_loss': mx.metric.MSE(name='value_loss', output_names=['value_output']),\n",
    "    'policy_loss': mx.metric.CrossEntropy(name='policy_loss', output_names=['policy_output'],\n",
    "                                                label_names=['policy_label']),\n",
    "    'value_acc_sign': mx.metric.create(acc_sign, name='value_acc_sign', output_names=['value_output'],\n",
    "                                             label_names=['value_label']),\n",
    "    'policy_acc': mx.metric.Accuracy(axis=1, name='policy_acc', output_names=['policy_output'],\n",
    "                                           label_names=['policy_label'])\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define a training agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_agent = TrainerAgent(net, val_data, nb_parts, lr_schedule, momentum_schedule, total_it, wd=wd, batch_steps=batch_steps,\n",
    "                 k_steps_initial=k_steps_initial, cpu_count=CPU_COUNT-3, batch_size=batch_size, normalize=normalize, export_weights=export_weights,\n",
    "                 export_grad_histograms=export_grad_histograms, log_metrics_to_tensorboard=log_metrics_to_tensorboard, ctx=ctx, metrics=metrics,\n",
    "                use_spike_recovery=use_spike_recovery, max_spikes=max_spikes, spike_thresh=spike_thresh, seed=seed, val_loss_factor=val_loss_factor, policy_loss_factor=policy_loss_factor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Start the training process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(k_steps_final, val_loss_final, val_p_acc_final), (k_steps_best, val_loss_best, val_p_acc_best) = train_agent.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Export the last model state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export the model via mxnet checkpoint\n",
    "prefix =\"./weights/model-%.5f-%.3f\" % (val_loss_final, val_p_acc_final)\n",
    "# the export function saves both the architecture and the weights\n",
    "net.export(prefix, epoch=k_steps_final) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prefix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the best model once again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# delete the current net object form memory\n",
    "del net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_prefix =\"./weights/model-%.5f-%.3f\" % (val_loss_best, val_p_acc_best)\n",
    "model_arch_path = '%s-symbol.json' % model_prefix\n",
    "model_params_path = '%s-%04d.params' % (model_prefix, k_steps_best)\n",
    "print('load current best model:', model_params_path)\n",
    "#net.load_parameters(model_path, ctx=ctx)\n",
    "net = gluon.nn.SymbolBlock.imports(model_arch_path, ['data'], model_params_path, ctx=ctx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('best val_loss: %.5f with v_policy_acc: %.5f at k_steps_best %d' % (val_loss_best, val_p_acc_best, k_steps_best))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "board = planes_to_board(x_val[idx], normalized_input=normalize)\n",
    "\n",
    "print(chess.COLOR_NAMES[board.turn])\n",
    "print(board.pockets)\n",
    "board"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_single(net, x):\n",
    "    \n",
    "    out = [None, None]\n",
    "    pred = net(mx.nd.array(np.expand_dims(x, axis=0), ctx=ctx))\n",
    "    pred[1] = pred[1].softmax()\n",
    "    out[0] = pred[0].asnumpy()\n",
    "    out[1] = pred[1].asnumpy()\n",
    "    \n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = predict_single(net, x_val[0])\n",
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "policy_to_best_move(board, yp_val[idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "opts = 5\n",
    "selected_moves, probs = policy_to_moves(board, pred[1][0])\n",
    "selected_moves[:opts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.barh(range(opts)[::-1], probs[:opts])\n",
    "ax = plt.gca()\n",
    "ax.set_yticks(range(opts)[::-1])\n",
    "ax.set_yticklabels(selected_moves)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "board = chess.variant.CrazyhouseBoard()\n",
    "board.push_uci('e2e4')\n",
    "board.push_uci('e7e5')\n",
    "board.push_uci('f1c4')\n",
    "board.push_uci('b8c6')\n",
    "board.push_uci('d1h5')\n",
    "x_scholar_atck = board_to_planes(board, normalize=normalize)\n",
    "board"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = predict_single(net, x_scholar_atck)\n",
    "\n",
    "selected_moves, probs = policy_to_moves(board, pred[1][0])\n",
    "plt.barh(range(opts)[::-1], probs[:opts])\n",
    "ax = plt.gca()\n",
    "ax.set_yticks(range(opts)[::-1])\n",
    "ax.set_yticklabels(selected_moves)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "board.push(selected_moves[0])\n",
    "board"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Performance on test dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s_idcs_test, x_test, yv_test, yp_test, pgn_datasets_test = load_pgn_dataset(dataset_type='test', part_id=0,\n",
    "                                                                           print_statistics=True, print_parameters=True, normalize=True)\n",
    "test_dataset = gluon.data.ArrayDataset(nd.array(x_test), nd.array(yv_test), nd.array(yp_test.argmax(axis=1)))\n",
    "test_data = gluon.data.DataLoader(test_dataset, batch_size=batch_size, shuffle=True, num_workers=CPU_COUNT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate_metrics(metrics, test_data, net, nb_batches=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Show result on mate-in-one problems"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s_idcs_mate, x_mate, yv_mate, yp_mate, pgn_dataset_mate = load_pgn_dataset(dataset_type='mate_in_one',\n",
    "                                                         print_parameters=True, print_statistics=True, normalize=normalize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mate_dataset = mx.gluon.data.dataset.ArrayDataset(nd.array(x_mate), nd.array(yv_mate), nd.array(yp_mate.argmax(axis=1)))\n",
    "mate_data = mx.gluon.data.DataLoader(mate_dataset, batch_size=batch_size, num_workers=CPU_COUNT)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mate In One Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#mod_p.score(mate_iter, metrics)\n",
    "evaluate_metrics(metrics, mate_data, net)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Show some example mate problems"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from DeepCrazyhouse.src.domain.crazyhouse.legal_move_filter import mirror_move"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_pos(net, x_mate, yp_mate, verbose=False):\n",
    "    \n",
    "    board = planes_to_board(x_mate, normalized_input=normalize)\n",
    "    if verbose is True:\n",
    "        print(\"{0}'s turn\".format(chess.COLOR_NAMES[board.turn]))\n",
    "        print(\"black/white {0}\".format(board.pockets))\n",
    "    pred = predict_single(net, x_mate)\n",
    "    \n",
    "    \n",
    "    #true_mat = yp_mate.reshape(78,8,8)\n",
    "    #true_move = filter_moves(board, true_mat, is_white_to_move=board.turn, renormalize_confidences=False)[0][0]\n",
    "    true_move = policy_to_move(yp_mate, is_white_to_move=board.turn)\n",
    "    \n",
    "    #pred_mat = pred[1][0].reshape(78,8,8)\n",
    "    opts = 5\n",
    "    pred_moves, probs = policy_to_moves(board, pred[1][0])\n",
    "    pred_moves = pred_moves[:opts]\n",
    "    \n",
    "    #pred_moves = filter_moves(board, pred_mat, is_white_to_move=board.turn, renormalize_confidences=False)[0][:opts]\n",
    "\n",
    "    legal_move_cnt = board.legal_moves.count()\n",
    "    mate_move_cnt = str(board.legal_moves).count('#')\n",
    "    \n",
    "    is_mate_5_top = False\n",
    "    \n",
    "    for pred_move in pred_moves:\n",
    "        board_5_top = deepcopy(board)\n",
    "        board_5_top.push(pred_move)\n",
    "        if board_5_top.is_checkmate() is True:\n",
    "            is_mate_5_top = True\n",
    "            break\n",
    "    \n",
    "    board.push(pred_moves[0])\n",
    "    \n",
    "    is_checkmate = False\n",
    "    if board.is_checkmate() is True:\n",
    "        is_checkmate = True\n",
    "        \n",
    "    filtered_pred = sorted(pred[1][0], reverse=True)\n",
    "    \n",
    "    if verbose is True:\n",
    "        plt.barh(range(opts)[::-1], filtered_pred[:opts])\n",
    "        ax = plt.gca()\n",
    "        ax.set_yticks(range(opts)[::-1])\n",
    "        ax.set_yticklabels(pred_moves)\n",
    "        plt.title('True Move:' + str(true_move) +\n",
    "                 '\\nEval:' + str(pred[0][0]))\n",
    "        plt.show()\n",
    "    \n",
    "    return pred, pred_moves, true_move, board, is_checkmate, is_mate_5_top, legal_move_cnt, mate_move_cnt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_pos = len(x_mate)\n",
    "mates_found = []\n",
    "mates_5_top_found = []\n",
    "legal_mv_cnts = []\n",
    "mate_mv_cnts = []\n",
    "\n",
    "for i in range(nb_pos):\n",
    "    pred, pred_moves, true_move, board, is_mate, is_mate_5_top, legal_mv_cnt, mate_mv_cnt= eval_pos(net, x_mate[i], yp_mate[i])\n",
    "    mates_found.append(is_mate)\n",
    "    legal_mv_cnts.append(legal_mv_cnt)\n",
    "    mate_mv_cnts.append(mate_mv_cnt)\n",
    "    mates_5_top_found.append(is_mate_5_top)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.array(mate_mv_cnts).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.array(legal_mv_cnts).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Guessing Baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.array(mate_mv_cnts).mean() / np.array(legal_mv_cnts).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prediciton Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('mate_in_one_acc:', sum(mates_found) / nb_pos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum(mates_5_top_found) / nb_pos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pgn_dataset_mate.tree()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata = np.array(pgn_dataset_mate['metadata'])\n",
    "metadata[0, :]\n",
    "metadata[1, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "site_mate = metadata[1:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_string(np_string):\n",
    "    string = str(site_mate[i]).replace(\"b'\", \"\")\n",
    "    string = string.replace(\"'\", \"\")\n",
    "    string = string.replace('\"', '')\n",
    "    \n",
    "    return string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import chess.svg\n",
    "from IPython.display import SVG, HTML"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Show the result of the first 17 examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(17):\n",
    "    print(clean_string(site_mate[i]))\n",
    "    pred, pred_moves, true_move, board, is_checkmate, is_mate_5_top, legal_move_cnt, mate_move_cnt = eval_pos(net, x_mate[i], yp_mate[i], verbose=True)\n",
    "    pred_move = pred_moves[0]\n",
    "    pred_arrow = chess.svg.Arrow(pred_move.from_square, pred_move.to_square)\n",
    "    SVG(data=chess.svg.board(board=board, arrows=[pred_arrow], size=400))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Show examples where it failed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(1000):\n",
    "    pred, pred_moves, true_move, board, is_checkmate, is_mate_5_top, legal_move_cnt, mate_move_cnt = eval_pos(net, x_mate[i], yp_mate[i], verbose=False)\n",
    "    if is_mate_5_top is False:\n",
    "        print(clean_string(site_mate[i]))\n",
    "        pred, pred_moves, true_move, board, is_checkmate, is_mate_5_top, legal_move_cnt, mate_move_cnt = eval_pos(net, x_mate[i], yp_mate[i], verbose=True)\n",
    "        pred_move = pred_moves[0]\n",
    "        pred_arrow = chess.svg.Arrow(pred_move.from_square, pred_move.to_square)\n",
    "        SVG(data=chess.svg.board(board=board, arrows=[pred_arrow], size=400))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
