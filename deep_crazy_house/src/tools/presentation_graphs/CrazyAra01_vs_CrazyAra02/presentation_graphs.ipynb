{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simple Notebook for preparing the whole training run in one graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import glob\n",
    "import re\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.style.use('seaborn-notebook')\n",
    "export_plots = False #True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the exported data from the Keras Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the json file\n",
    "with open('lr_0.1_keras/logs/train_history.json') as json_data:\n",
    "    metric_data_keras = json.load(json_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a list of integer to string converted values which is used for mapping the our k_step to our value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create history object which stores all training metrics for this\n",
    "hist_lr_0_1_keras = {}\n",
    "\n",
    "k_step_keys = [str(i) for i in list(range(len(metric_data_keras['loss'])))]\n",
    "\n",
    "\n",
    "for key in metric_data_keras.keys():\n",
    "    hist_lr_0_1_keras[key] = [metric_data_keras[key][cur_k_step] for cur_k_step in k_step_keys]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the exported metrics from the MXNET Run exported Tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_hist_metrics(lr='0.01'):\n",
    "    \"\"\"\n",
    "    Loads the exported metrics from .json files in a dictionary obj. with 2D numpy arrays\n",
    "    \"\"\"\n",
    "    json_files = glob.glob('./lr_%s_mxnet/logs/json/*' % lr)\n",
    "    hist_metrics = {}\n",
    "    for json_file in json_files:\n",
    "        \n",
    "        # extract the metric name using a regular expression\n",
    "        m = re.search(r'(?<=run_.-tag-)\\w+(?<!.json)', json_file)\n",
    "        metric_name = m.group(0)\n",
    "        \n",
    "        # load the one json file of which each contain a metric\n",
    "        with open(json_file) as json_data:\n",
    "            data = json.load(json_data)\n",
    "\n",
    "        # store the metric data in a 2D-numpy array\n",
    "        metric_data = np.zeros((len(data), 2))\n",
    "        for i, row in enumerate(data):\n",
    "            metric_data[i, :] = row[1], row[2]\n",
    "\n",
    "        # fill in our dict object using the stored values\n",
    "        hist_metrics[metric_name] = metric_data\n",
    "        \n",
    "    return hist_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hist_lr_0_01_mxnet = get_hist_metrics(lr='0.01')\n",
    "hist_lr_0_001_mxnet = get_hist_metrics(lr='0.001')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_k_steps = int(hist_lr_0_001_mxnet['train_policy_loss'][-1, 0])+1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_compact = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "try:\n",
    "    plt.plot(hist_lr_0_1_keras[metric])\n",
    "except KeyError:\n",
    "    plt.plot(hist_lr_0_1_keras[metric.replace('train_', '')])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "metric = np.zeros(total_k_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_compact"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_compact = {}\n",
    "\n",
    "for hist in [hist_lr_0_01_mxnet, hist_lr_0_001_mxnet]:\n",
    "    for metric in hist.keys():\n",
    "        for type_metric in ['train_', 'val_']:\n",
    "            if type_metric in metric:\n",
    "                metric_crop = metric.replace(type_metric, '')\n",
    "                if metric_crop not in metrics_compact:\n",
    "                    metrics_compact[metric_crop] = {}\n",
    "                if type_metric not in metrics_compact[metric_crop]:\n",
    "                    metrics_compact[metric_crop][type_metric] = np.zeros(total_k_steps)\n",
    "                #print(metrics_compact)\n",
    "                for row in hist[metric]:\n",
    "                    #print(row[0])\n",
    "                    (metrics_compact[metric_crop][type_metric])[int(row[0])] = row[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fill in the first values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hist_lr_0_1_keras.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for metric in hist_lr_0_1_keras:\n",
    "    if 'val_' in metric:\n",
    "        for i, val in enumerate(hist_lr_0_1_keras[metric]):\n",
    "            metric_crop = metric.replace('val_', '')\n",
    "            if metric_crop in metrics_compact:\n",
    "                if metrics_compact[metric_crop]['val_'][i] == 0:\n",
    "                    metrics_compact[metric_crop]['val_'][i] = val\n",
    "    else:  # train metric\n",
    "        for i, val in enumerate(hist_lr_0_1_keras[metric]):\n",
    "            if metric in metrics_compact:\n",
    "                if metrics_compact[metric]['train_'][i] == 0:\n",
    "                    metrics_compact[metric]['train_'][i] = val        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now visualisize the full data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_def(filename):\n",
    "    plt.legend()\n",
    "    plt.grid(axis='y')\n",
    "    plt.xlabel('Thousands of Steps / Batch-Size 2048')\n",
    "    if export_plots is True:\n",
    "        plt.savefig('./plots/%s.png'%filename)\n",
    "        plt.savefig('./plots/%s.pdf'%filename)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for metric in metrics_compact:\n",
    "    for type_set in metrics_compact[metric]:\n",
    "        plt.plot(metrics_compact[metric][type_set][:-3], label='%s%s'%(type_set, metric)) # [:-3] because the last 3 entries are 0 somehow\n",
    "    apply_def(metric)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Export the structure of the network architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0,'../../../../../')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from DeepCrazyhouse.src.training.architecture.mxnet_alpha_zero import alpha_zero_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mxnet as mx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the symbol defintion of the alpha zero architecture\n",
    "sym = alpha_zero_model(num_res_blocks=7, n_labels=4992, grad_scale_value=0.01, grad_scale_policy=0.99)\n",
    "# Visualize your network\n",
    "pltn = mx.viz.plot_network(sym)\n",
    "pltn.view('./plots/alpha_zero_model_7x256')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from DeepCrazyhouse.configs.main_config import main_config\n",
    "from glob import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sym_path = glob(main_config['model_architecture_dir'] + '*')[0]\n",
    "sym_path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Export the full architecture graph for RISE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sym = mx.sym.load(sym_path)\n",
    "\n",
    "input_shape = (34, 8, 8)\n",
    "\n",
    "plot_fig = mx.viz.plot_network(sym, shape={'data':(1, input_shape[0], input_shape[1], input_shape[2])}, node_attrs={\"fixedsize\":\"false\"} )\n",
    "plot_fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_fig.view('./1_cycle_rise/plots/rise_7x12')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the json file\n",
    "with open('1_cycle_rise/json/run_.-tag-lr.json') as json_data:\n",
    "    lr_data = json.load(json_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_data_raw = []\n",
    "for item in lr_data:\n",
    "    lr_data_raw.append(item[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('1_cycle_rise/json/run_.-tag-momentum.json') as json_data:\n",
    "    momentum_data = json.load(json_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "momentum_data_raw = []\n",
    "for item in momentum_data:\n",
    "    momentum_data_raw.append(item[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_raw_data(json_data):\n",
    "    data_raw = []\n",
    "    for item in json_data:\n",
    "        data_raw.append(item[2])\n",
    "    return data_raw"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Definition of the individual settings for the training runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size_crazyara_01 = 2048\n",
    "batch_size_crazyara_02 = 1024\n",
    "\n",
    "x_crazyara_01 = np.arange(0, len(metrics_compact['policy_loss']['val_'])) * batch_size_crazyara_01 * 1000\n",
    "x_crazyara_02_init_run = np.arange(0, len(lr_data_raw)) * batch_size_crazyara_02 * 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "export_plots = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_def(filename):\n",
    "    plt.legend(frameon=True)\n",
    "    plt.grid(axis='x')\n",
    "    plt.xlabel('Number of Training Samples processed')\n",
    "    if export_plots is True:\n",
    "        plt.savefig('./plots_comp/%s.png'%filename, bbox='tight')\n",
    "        plt.savefig('./plots_comp/%s.pdf'%filename, bbox='tight')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Learning Rate Schedule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(x_crazyara_02_init_run, lr_data_raw[:len(x_crazyara_02)], label='learning rate')\n",
    "plt.title('Learning Rate Schedule')\n",
    "plt.xlabel('Number of Training Samples processed')\n",
    "apply_def('lr_schedule')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(x_crazyara_02_init_run, momentum_data_raw[:len(x_crazyara_02)], label='momentum')\n",
    "plt.title('Momentum Schedule')\n",
    "apply_def('momentum_schedule')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Policy Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('1_cycle_rise/json/run_policy_loss_val-tag-policy_loss.json') as json_data:\n",
    "    val_policy_loss = json.load(json_data)\n",
    "    val_policy_loss = get_raw_data(val_policy_loss)\n",
    "with open('1_cycle_rise/final_cooldown_1/json/run_policy_loss_val-tag-policy_loss.json') as json_data:\n",
    "    val_policy_loss_cd1 = json.load(json_data)\n",
    "    val_policy_loss_cd1 = get_raw_data(val_policy_loss_cd1)    \n",
    "with open('1_cycle_rise/final_cooldown_2/json/run_policy_loss_val-tag-policy_loss.json') as json_data:\n",
    "    val_policy_loss_cd2 = json.load(json_data)\n",
    "    val_policy_loss_cd2 = get_raw_data(val_policy_loss_cd2)  \n",
    "val_policy_loss_total = val_policy_loss + val_policy_loss_cd1 + val_policy_loss_cd2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('1_cycle_rise/json/run_policy_loss_train-tag-policy_loss.json') as json_data:\n",
    "    train_policy_loss = json.load(json_data)\n",
    "    train_policy_loss = get_raw_data(train_policy_loss)\n",
    "with open('1_cycle_rise/final_cooldown_1/json/run_policy_loss_train-tag-policy_loss.json') as json_data:\n",
    "    train_policy_loss_cd1 = json.load(json_data)\n",
    "    train_policy_loss_cd1 = get_raw_data(train_policy_loss_cd1)    \n",
    "with open('1_cycle_rise/final_cooldown_2/json/run_policy_loss_train-tag-policy_loss.json') as json_data:\n",
    "    train_policy_loss_cd2 = json.load(json_data)\n",
    "    train_policy_loss_cd2 = get_raw_data(train_policy_loss_cd2)  \n",
    "train_policy_loss_total = train_policy_loss + train_policy_loss_cd1 + train_policy_loss_cd2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Policy Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('1_cycle_rise/json/run_policy_acc_val-tag-policy_acc.json') as json_data:\n",
    "    val_policy_acc = json.load(json_data)\n",
    "    val_policy_acc = get_raw_data(val_policy_acc)\n",
    "with open('1_cycle_rise/final_cooldown_1/json/run_policy_acc_val-tag-policy_acc.json') as json_data:\n",
    "    val_policy_acc_cd1 = json.load(json_data)\n",
    "    val_policy_acc_cd1 = get_raw_data(val_policy_acc_cd1)    \n",
    "with open('1_cycle_rise/final_cooldown_2/json/run_policy_acc_val-tag-policy_acc.json') as json_data:\n",
    "    val_policy_acc_cd2 = json.load(json_data)\n",
    "    val_policy_acc_cd2 = get_raw_data(val_policy_acc_cd2)  \n",
    "val_policy_acc_total = val_policy_acc + val_policy_acc_cd1 + val_policy_acc_cd2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('1_cycle_rise/json/run_policy_acc_train-tag-policy_acc.json') as json_data:\n",
    "    train_policy_acc = json.load(json_data)\n",
    "    train_policy_acc = get_raw_data(train_policy_acc)\n",
    "with open('1_cycle_rise/final_cooldown_1/json/run_policy_acc_train-tag-policy_acc.json') as json_data:\n",
    "    train_policy_acc_cd1 = json.load(json_data)\n",
    "    train_policy_acc_cd1 = get_raw_data(train_policy_acc_cd1)    \n",
    "with open('1_cycle_rise/final_cooldown_2/json/run_policy_acc_train-tag-policy_acc.json') as json_data:\n",
    "    train_policy_acc_cd2 = json.load(json_data)\n",
    "    train_policy_acc_cd2 = get_raw_data(train_policy_acc_cd2)  \n",
    "train_policy_acc_total = train_policy_acc + train_policy_acc_cd1 + train_policy_acc_cd2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Value Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('1_cycle_rise/json/run_value_loss_val-tag-value_loss.json') as json_data:\n",
    "    val_value_loss = json.load(json_data)\n",
    "    val_value_loss = get_raw_data(val_value_loss)\n",
    "with open('1_cycle_rise/final_cooldown_1/json/run_value_loss_val-tag-value_loss.json') as json_data:\n",
    "    val_value_loss_cd1 = json.load(json_data)\n",
    "    val_value_loss_cd1 = get_raw_data(val_value_loss_cd1)    \n",
    "with open('1_cycle_rise/final_cooldown_2/json/run_value_loss_val-tag-value_loss.json') as json_data:\n",
    "    val_value_loss_cd2 = json.load(json_data)\n",
    "    val_value_loss_cd2 = get_raw_data(val_value_loss_cd2)  \n",
    "val_value_loss_total = val_value_loss + val_value_loss_cd1 + val_value_loss_cd2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('1_cycle_rise/json/run_value_loss_train-tag-value_loss.json') as json_data:\n",
    "    train_value_loss = json.load(json_data)\n",
    "    train_value_loss = get_raw_data(train_value_loss)\n",
    "with open('1_cycle_rise/final_cooldown_1/json/run_value_loss_train-tag-value_loss.json') as json_data:\n",
    "    train_value_loss_cd1 = json.load(json_data)\n",
    "    train_value_loss_cd1 = get_raw_data(train_value_loss_cd1)    \n",
    "with open('1_cycle_rise/final_cooldown_2/json/run_value_loss_train-tag-value_loss.json') as json_data:\n",
    "    train_value_loss_cd2 = json.load(json_data)\n",
    "    train_value_loss_cd2 = get_raw_data(train_value_loss_cd2)  \n",
    "train_value_loss_total = train_value_loss + train_value_loss_cd1 + train_value_loss_cd2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Value Acc Sign"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('1_cycle_rise/json/run_value_acc_sign_train-tag-value_acc_sign.json') as json_data:\n",
    "    train_value_acc_sign = json.load(json_data)\n",
    "    train_value_acc_sign = get_raw_data(train_value_acc_sign)\n",
    "with open('1_cycle_rise/final_cooldown_1/json/run_value_acc_sign_train-tag-value_acc_sign.json') as json_data:\n",
    "    train_value_acc_sign_cd1 = json.load(json_data)\n",
    "    train_value_acc_sign_cd1 = get_raw_data(train_value_acc_sign_cd1)    \n",
    "with open('1_cycle_rise/final_cooldown_2/json/run_value_acc_sign_train-tag-value_acc_sign.json') as json_data:\n",
    "    train_value_acc_sign_cd2 = json.load(json_data)\n",
    "    train_value_acc_sign_cd2 = get_raw_data(train_value_acc_sign_cd2)  \n",
    "train_value_acc_sign_total = train_value_acc_sign + train_value_acc_sign_cd1 + train_value_acc_sign_cd2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('1_cycle_rise/json/run_value_acc_sign_val-tag-value_acc_sign.json') as json_data:\n",
    "    val_value_acc_sign = json.load(json_data)\n",
    "    val_value_acc_sign = get_raw_data(val_value_acc_sign)\n",
    "with open('1_cycle_rise/final_cooldown_1/json/run_value_acc_sign_val-tag-value_acc_sign.json') as json_data:\n",
    "    val_value_acc_sign_cd1 = json.load(json_data)\n",
    "    val_value_acc_sign_cd1 = get_raw_data(val_value_acc_sign_cd1)    \n",
    "with open('1_cycle_rise/final_cooldown_2/json/run_value_acc_sign_val-tag-value_acc_sign.json') as json_data:\n",
    "    val_value_acc_sign_cd2 = json.load(json_data)\n",
    "    val_value_acc_sign_cd2 = get_raw_data(val_value_acc_sign_cd2)  \n",
    "val_value_acc_sign_total = val_value_acc_sign + val_value_acc_sign_cd1 + val_value_acc_sign_cd2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns;\n",
    "sns.set()\n",
    "sns.set_style(\"whitegrid\")\n",
    "colors = sns.color_palette(\"colorblind\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_crazyara_02 = np.arange(0, len(val_policy_loss_total)) * batch_size_crazyara_02 * 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(x_crazyara_01, metrics_compact['policy_loss']['train_'], '--', c=colors[0], alpha=0.3, label='train-loss-CrazyAra-0.1')\n",
    "plt.plot(x_crazyara_01, metrics_compact['policy_loss']['val_'],  c=colors[0], label='validation-loss-CrazyAra-0.1')\n",
    "plt.plot(x_crazyara_02, train_policy_loss_total, '--', c=colors[1], alpha=0.3, label='train-loss-CrazyAra-0.2')\n",
    "plt.plot(x_crazyara_02, val_policy_loss_total, c=colors[1],  label='validation-loss-CrazyAra-0.2')\n",
    "plt.title('Policy Loss')\n",
    "plt.ylim([1.1,2.5])\n",
    "apply_def('policy_loss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(x_crazyara_01, metrics_compact['policy_acc']['train_'], '--', c=colors[0], alpha=0.3, label='train-accuracy-CrazyAra-0.1')\n",
    "plt.plot(x_crazyara_01, metrics_compact['policy_acc']['val_'],  c=colors[0], label='validation-accuracy-CrazyAra-0.1')\n",
    "plt.plot(x_crazyara_02, train_policy_acc_total, '--', c=colors[1], alpha=0.3, label='train-accuracy-CrazyAra-0.2')\n",
    "plt.plot(x_crazyara_02, val_policy_acc_total, c=colors[1],  label='validation-accuracy-CrazyAra-0.2')\n",
    "plt.title('Policy Accuracy')\n",
    "apply_def('policy_acc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(x_crazyara_01, metrics_compact['value_loss']['train_'], '--', c=colors[0], alpha=0.3, label='train-loss-CrazyAra-0.1')\n",
    "plt.plot(x_crazyara_01, metrics_compact['value_loss']['val_'],  c=colors[0], label='validation-loss-CrazyAra-0.1')\n",
    "plt.plot(x_crazyara_02, train_value_loss_total, '--', c=colors[1], alpha=0.3, label='train-loss-CrazyAra-0.2')\n",
    "plt.plot(x_crazyara_02, val_value_loss_total, c=colors[1], label='validation-loss-CrazyAra-0.2')\n",
    "plt.title('Value Loss')\n",
    "apply_def('value_loss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(x_crazyara_01, metrics_compact['value_acc_sign']['train_'], '--', c=colors[0], alpha=0.3, label='train-acc_sign-CrazyAra-0.1')\n",
    "plt.plot(x_crazyara_01, metrics_compact['value_acc_sign']['val_'],  c=colors[0], label='validation-acc_sign-CrazyAra-0.1')\n",
    "plt.plot(x_crazyara_02, train_value_acc_sign_total, '--', c=colors[1], alpha=0.3, label='train-acc_sign-CrazyAra-0.2')\n",
    "plt.plot(x_crazyara_02, val_value_acc_sign_total, c=colors[1], label='validation-acc_sign-CrazyAra-0.2')\n",
    "plt.title('Accurarcy of predicting the correct Game Result')\n",
    "apply_def('value_acc_sign')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
