{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simple Notebook for preparing the whole training run in one graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import glob\n",
    "import re\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.style.use('seaborn-notebook')\n",
    "export_plots = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the exported metrics from the MXNET Run exported Tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_hist_metrics(json_dir='./logs/json/'):\n",
    "    \"\"\"\n",
    "    Loads the exported metrics from .json files in a dictionary obj. with 2D numpy arrays\n",
    "    \"\"\"\n",
    "    json_files = glob.glob('%s/*' % (json_dir))\n",
    "    hist_metrics = {}\n",
    "    for json_file in json_files:\n",
    "        \n",
    "        # extract the metric name using a regular expression\n",
    "        m = re.search(r'(?<=run_)\\w+(?<!.json)', json_file)\n",
    "        metric_name = m.group(0)\n",
    "        \n",
    "        # load the one json file of which each contain a metric\n",
    "        with open(json_file) as json_data:\n",
    "            data = json.load(json_data)\n",
    "\n",
    "        # store the metric data in a 1D-numpy array\n",
    "        metric_data = np.zeros((len(data), 1))\n",
    "        for i, row in enumerate(data):\n",
    "            metric_data[i] = row[2]\n",
    "\n",
    "        # fill in our dict object using the stored values\n",
    "        hist_metrics[metric_name] = metric_data\n",
    "        \n",
    "    return hist_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = re.search(r'(?<=run_)\\w+(?<!.json)', './19_res_layers/run_loss_train-tag-loss.json')\n",
    "metric_name = m.group(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hist_19_res_layers = get_hist_metrics('./19_res_layers/')\n",
    "hist_15_reslayers_5_layers_stem = get_hist_metrics('./15_reslayers_5_layers_stem/')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "total_k_steps = int(hist_lr_0_001_mxnet['train_policy_loss'][-1, 0])+1\n",
    "\n",
    "\n",
    "metrics_compact = {}\n",
    "\n",
    "try:\n",
    "    plt.plot(hist_lr_0_1_keras[metric])\n",
    "except KeyError:\n",
    "    plt.plot(hist_lr_0_1_keras[metric.replace('train_', '')])\n",
    "\n",
    "metric = np.zeros(total_k_steps)\n",
    "\n",
    "metrics_compact\n",
    "\n",
    "metrics_compact = {}\n",
    "\n",
    "for hist in [hist_lr_0_01_mxnet, hist_lr_0_001_mxnet]:\n",
    "    for metric in hist.keys():\n",
    "        for type_metric in ['train_', 'val_']:\n",
    "            if type_metric in metric:\n",
    "                metric_crop = metric.replace(type_metric, '')\n",
    "                if metric_crop not in metrics_compact:\n",
    "                    metrics_compact[metric_crop] = {}\n",
    "                if type_metric not in metrics_compact[metric_crop]:\n",
    "                    metrics_compact[metric_crop][type_metric] = np.zeros(total_k_steps)\n",
    "                #print(metrics_compact)\n",
    "                for row in hist[metric]:\n",
    "                    #print(row[0])\n",
    "                    (metrics_compact[metric_crop][type_metric])[int(row[0])] = row[1]\n",
    "\n",
    "## Fill in the first values\n",
    "\n",
    "hist_lr_0_1_keras.keys()\n",
    "\n",
    "for metric in hist_lr_0_1_keras:\n",
    "    if 'val_' in metric:\n",
    "        for i, val in enumerate(hist_lr_0_1_keras[metric]):\n",
    "            metric_crop = metric.replace('val_', '')\n",
    "            if metric_crop in metrics_compact:\n",
    "                if metrics_compact[metric_crop]['val_'][i] == 0:\n",
    "                    metrics_compact[metric_crop]['val_'][i] = val\n",
    "    else:  # train metric\n",
    "        for i, val in enumerate(hist_lr_0_1_keras[metric]):\n",
    "            if metric in metrics_compact:\n",
    "                if metrics_compact[metric]['train_'][i] == 0:\n",
    "                    metrics_compact[metric]['train_'][i] = val\n",
    "```                    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now visualisize the full data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "colors = ['cornflowerblue', 'darkorange']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, metric in enumerate(hist_19_res_layers):\n",
    "    plt.plot(hist_19_res_layers[metric], '-', label='%s (%s)'%(metric, 'ResnetA0'), c=colors[i])\n",
    "for i, metric in enumerate(hist_15_reslayers_5_layers_stem):\n",
    "    plt.plot(hist_15_reslayers_5_layers_stem[metric], '--', label='%s (%s)'%(metric, 'ResnetA0v2'), c=colors[i])           \n",
    "    #print(metric)\n",
    "plt.title('Training Comparision:\\nResnetA0 (1 Conv - 19 ResLayers)\\nResnetA0v2 (4 Conv - 15 ResLayers (LRelu, SE)) \\nlr = 0.1, batch_size=1024')\n",
    "plt.xlabel('Number of Epoch')\n",
    "apply_def('ResnetA0vsResnetA0v2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def apply_def(filename):\n",
    "    plt.legend()\n",
    "    plt.grid(axis='y')\n",
    "    if export_plots is True:\n",
    "        plt.savefig('./plots/%s.png'%filename, bbox_inches='tight')\n",
    "        plt.savefig('./plots/%s.pdf'%filename, bbox_inches='tight')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "plt.plot(h)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "for metric in metrics_compact:\n",
    "    for type_set in metrics_compact[metric]:\n",
    "        plt.plot(metrics_compact[metric][type_set][:-3], label='%s%s'%(type_set, metric)) # [:-3] because the last 3 entries are 0 somehow\n",
    "        plt.grid(axis='y')\n",
    "        plt.xlabel('Thousands of Steps / Batch-Size 2048')        \n",
    "    apply_def(metric)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Export the structure of the network architecture"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "import sys\n",
    "sys.path.insert(0,'../../../../../')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "from DeepCrazyhouse.src.training.architecture.mxnet_alpha_zero import alpha_zero_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "import mxnet as mx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# get the symbol defintion of the alpha zero architecture\n",
    "sym = alpha_zero_model(num_res_blocks=7, n_labels=4992, grad_scale_value=0.01, grad_scale_policy=0.99)\n",
    "# Visualize your network\n",
    "pltn = mx.viz.plot_network(sym)\n",
    "pltn.view('./plots/alpha_zero_model_7x256')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
